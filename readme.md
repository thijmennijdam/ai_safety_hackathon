# Automated Feature Discovery for AI Safety

## Overview
This repository contains the work of Team Circuit Breakers for the AI Safety Hackathon hosted at TU Delft. Our project aims to advance the field of AI safety by developing a novel method for automated feature discovery using sparse autoencoders.

## Table of Contents
- [Project Description](#project-description)
- [Event Information](#event-information)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [Resources](#resources)
- [Team](#team)
- [Acknowledgements](#acknowledgements)
- [License](#license)

## Project Description
Whereas automated circuit discovery for mechanistic interpretability has been used to examine behaviors on a neuron level, our proposal introduces a novel method that automatically discovers features instead of circuits. Leveraging the latest breakthrough in mechanistic interpretability, our project utilizes sparse autoencoders for efficient training, data efficiency, automated interpretability metrics, task-specific feature identification, fine-grained behavioral control, and adversarial feature testing. For more details on the project's goals, please refer to our [Notion Goals Page](INSERT_LINK_HERE).

## Event Information
For detailed event information, please visit the [Hackathon Event Page](https://lu.ma/ua7pzcop).

## Installation
Instructions on how to install and set up the project.

```bash
git clone https://github.com/thijmennijdam/ai_safety_hackathon
cd ai_safety_hackathon
# Follow further instructions for environment setup and dependencies installation
```

## Usage
A step-by-step guide on how to use the software, including code snippets and screenshots for clarity.

## Resources
Links to resources used in the project, including papers, articles, and tools:

- [Toy Models of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html#motivation)
- [Towards Monosemanticity](https://transformer-circuits.pub/2023/monosemantic-features)
- [Sparse Autoencoders in Language Models](https://arxiv.org/abs/2309.08600)
- [Automatic Circuit DisCovery for Mechanistic Interpretability](https://arxiv.org/abs/2304.14997)
- [Automatic Circuit DisCovery++](https://github.com/Aaquib111/acdcpp)
- [Interpretability in the Wild](https://www.neelnanda.io/mechanistic-interpretability/walkthrough-ioi)


## Result visualizations

![inp-toy](imgs/inp-toy.jpg)

![inp-sae](imgs/inp-sae.jpg)

![showing superposition](imgs/showing-superpos.jpg)


## Team
This project was completed by Patrik Bartak, Derck Prinzhorn, Thijmen Nijdam, Gijs de Jong, Leonard Bereska

## Acknowledgements
We would like to thank the people of Entrepreneur First and Apart Research for organising the hackathon and more importantly their mentorship during our process.


A special thanks to [Can Rager](https://github.com/canrager) for their help with acdc++ and their valuable insight into attribution patching! 

## License
MIT
